Steps to ingest 1000 Genomes phase 1 data.


===========================================
- Pull table schemas for BigQuery tables into local JSON files. Use JQ to reformat them into the expected JSON format for Data Repo's create dataset command.

cd ~/Workspaces/elasticsearch-poc/1000Genomes 

bq show --format=prettyjson bigquery-public-data:human_genome_variants.1000_genomes_sample_info | jq '.schema.fields[] |= del(.description)' | jq '.schema.fields[] |= with_entries(if .key == "type" then .key = "datatype" else . end)' | jq '.schema.fields' > ./table-schema/1000_genomes_sample_info.json

bq show --format=prettyjson bigquery-public-data:human_genome_variants.1000_genomes_pedigree | jq '.schema.fields[] |= del(.description)' | jq '.schema.fields[] |= with_entries(if .key == "type" then .key = "datatype" else . end)' | jq '.schema.fields' > ./table-schema/1000_genomes_pedigree.json


===========================================
- Build a create dataset JSON request with that includes the BigQuery table schemas.

cd ~/Workspaces/elasticsearch-poc/1000Genomes 

jq --argjson sampleInfoColumns "$(cat ./table-schema/1000_genomes_sample_info.json)" '.schema.tables[0].columns = $sampleInfoColumns' ./dataset-create-template.json > ./dataset-create.json

cp ./dataset-create.json ./dataset-create-tmp.json

jq --argjson pedigreeColumns "$(cat ./table-schema/1000_genomes_pedigree.json)" '.schema.tables[1].columns = $pedigreeColumns' ./dataset-create-tmp.json > ./dataset-create.json

rm ./dataset-create-tmp.json


===========================================
- Create a dataset with the JSON request built above.

alias jc=~/Workspaces/jade-data-repo-cli/build/install/jadecli/bin/jadecli

jc profile create --name 1000GenomesProfile --account 00708C-45D19D-27AAFA

jc dataset create --input-json ./dataset-create.json --profile 1000GenomesProfile

If successful, the output looks like:
class DatasetSummaryModel {
    id: 471f52b3-e12e-43d6-bf4a-8e3e8e5bb384
    name: 1000GenomesDataset
    description: Public dataset 1000 Genomes.
    defaultProfileId: 3185b759-f9e7-4487-9a35-0e776f669864
    additionalProfileIds: null
    createdDate: 2020-01-28T20:57:25.702579Z
}


===========================================
- Export the BQ tabular data into JSON files in a bucket. This is the sample_info and pedigree tables. Then grant the Data Repo service account read access to the bucket.

gsutil mb -p broad-jade-mm gs://broad-jade-mm-ingestdata/

bq extract --destination_format NEWLINE_DELIMITED_JSON 'bigquery-public-data:human_genome_variants.1000_genomes_sample_info' gs://broad-jade-mm-ingestdata/1000_genomes_sample_info.json

bq extract --destination_format NEWLINE_DELIMITED_JSON 'bigquery-public-data:human_genome_variants.1000_genomes_pedigree' gs://broad-jade-mm-ingestdata/1000_genomes_pedigree.json

gsutil iam ch serviceAccount:jade-k8-sa@broad-jade-dev.iam.gserviceaccount.com:roles/storage.objectViewer gs://broad-jade-mm-ingestdata/


===========================================
- Upload the BQ tabular data that does NOT include file references. This is the sample_info and pedigree tables.

jc dataset table load --table sample_info --input-gspath gs://broad-jade-mm-ingestdata/1000_genomes_sample_info.json --input-format json 1000GenomesDataset

jc dataset table load --table pedigree  --input-gspath gs://broad-jade-mm-ingestdata/1000_genomes_pedigree.json --input-format json 1000GenomesDataset

If successful, the output looks like:
Loaded 3500 rows; 0 bad rows skipped
Loaded 3501 rows; 0 bad rows skipped


===========================================
- Upload the BAM and VCF files and save the file IDs returned.

gsutil ls -r gs://genomics-public-data/1000-genomes/bam/** > file-load/filepath-list.txt

cat file-load/filepath-list.txt | sed 's/\(gs:\/\/genomics\-public\-data\/1000\-genomes\/bam\/\(\([^\.]*\)\..*\)\)/jc dataset file load --profile 1000GenomesProfile --input-gspath \1 --target-path \/bam\_files\/\2 --mime-type "application\/octet-stream" --description "\3 BAM file" --format json 1000GenomesDataset/' > file-load/load-cmd-list.txt

Then run the commands in the file-load/load-cmd-list.txt. Either one at a time, in batches, or all at once. For me, each command takes about 15-30 minutes to show up in the output of "jc dr tree".


